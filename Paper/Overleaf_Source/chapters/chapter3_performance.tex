\chapter{Approaches for better performance with machine learning models}
\label{chap:preformance}

\par As the learning capabilities of deep neural networks increased over the years, so have their sizes in terms of the number of parameters and depth. With this the accuracy and speed of the models have increased, allowing for more and more use cases, like real-time predictions even on an everyday computer.
\par To be able to utilize a deep neural network algorithm in real-time, an architecture has to be chosen, which minimizes the number of parameters and overall size, while also maintaining a useful accuracy. There are a handful of such architectures, from which I will compare three.
\par For comparing the performance of the models, I am going to use the running time of one pass through the architecture in milliseconds. The goal is to use them in a real-time video processing application, with a reasonable frame rate of 24 frames per second, it means a running time needed of around 41 milliseconds. In practice this metric is dependent on a lot of variables, so it is not a hard requirement, just something to put the performances of the architectures in contrast.   

\section{Model comparisons}
\label{subsec:preformancesec1}

\subsection{Representative frames with deep learning}
\label{subsec:preformancesec1subsec1}

\par Starting with a simpler architecture in terms of the deep learning neural network, in the study of John and co. \cite{john2016} a high accuracy was achieved in real-time using representative frames, instead of a whole segment, with a specific algorithm, hence selecting better data for the machine learning model to predict from. Their algorithm clearly separated the two parts, the frame extraction running in  around 70 milliseconds and the classification running in around 40 milliseconds, achieving an accuracy of 91 percent.

\subsection{YOLOv3 performance}
\label{subsec:preformancesec1subsec2}

\par The YOLOv3 model is an efficient deep learning architecture, making it more than useful in achieving real-time performance on hand gesture detection and identification problems. In the approach of Mujahid, Awan and co. \cite{app11094164}, this algorithm was thought from scratch on the Mindst dataset \cite{deng2012mnist}, achieving good results. They proposed a lightweight architecture which is built on the YOLOv3 model, achieving impressive results, with an approximate accuracy rating of 98 percent in real-time, although time specifications were not provided.

\subsection{MobileNet performance}
\label{subsec:preformancesec1subsec3}

\par The approach of Wanga, Hua and Jina \cite{wang2021} consists of utilizing the architecture of MobileNet and Random Forest to identify hand gestures. They utilized the pretrained parameters of MobileNet on the ImageNet dataset \cite{deng2009imagenet}, than taking the output and running it through a Random Forest model to better extract features from the images. Their paper does not focus on performance in the context of the time needed for a prediction, that being said, since they use the MobileNet architecture as their backbone, which in a configuration of around 3.5 million parameters can achieve a pass-through time of around 35 milliseconds, from personal testing, it is safe to assume, that near real-time performance is achievable with their approach.
\par In Table \ref{MobileNetTable} the comparison of two MobileNet models, one with and one without a random forest ending, can be seen with regard to their accuracy ratings on three different hand based image datasets. From the results we can conclude that both architectures can achieve good accuracy. Combining that with the low hardware requirements of the model, we get a perfect combination for a usage in real-time applications.

\begin{table}[htbp]
\begin{center}
\begin{tabular}
{|p{90pt}|p{90pt}|p{90pt}|p{90pt}|}
\hline
Model & SLD Dataset Accuracy & SLGI Dataset Accuracy & Fingers Dataset Accuracy\\
\hline 
\hline MobileNet & $74.25\%$ & $94.12\%$ & $97.02\%$\\
\hline MobileNet-RF & $80.97\%$ & $95.12\%$ & $99.72\%$\\
\hline
\end{tabular}
\end{center}
\caption{MobileNet and MobileNet-RF accuracy, from the study of Wanga and co. \cite{wang2021}, on the Sign Language Digital Dataset (SLD) \cite{kopf:22025:sign-lang:lrec}, Sign Language Gestures Image Dataset (SLGI) \cite{jimaging9120262} and the Fingers Dataset}
\label{MobileNetTable}
\end{table}

\section{Transfer learning}
\label{subsec:preformancesec2}

\par Transfer learning is a machine learning technique where a pretrained model on a specific task and dataset is repurposed and fine-tuned for a different but similar problem. The pretrained values are taken for a new task, since the learned functions are usable in the new context, like in the example of identifying animals and human faces, the pretrained values will help to extract certain features which characterizes these objects, like facial line structures.
\par Using this method the deep neural network will start in closer to optimal position when learning features, jump starting the process, and enhancing the overall accuracy of the model. It is also a very useful tool, when dealing with a smaller dataset, or when collecting more data proves to be more challenging, allowing the architecture to learn with less data. This is also the reason why this approach is used in this application, since collecting thousands of images and labeling every one of them would take up an incredible amount of time.