\chapter{Introduction}
\label{intro}

\par Hand gestures, whether directly or indirectly have always been a big part of our communication. This is the reason why the field of detecting them has been frequently researched by those interested in computer vision. In the early days, it was achieved by a more straightforward approach, like calculating the contrasts between pixels, to segment the part that was needed.
\par As computer performances advanced so did this field, by enabling more complex and more nuanced computations. As years passed, the emergence of machine learning created a new approach, mostly with deep learning models, by leaving the majority of complexities to the artificial intelligence models. This approach allowed developers to create a more reliable identification method. This and the constant increase in computational power opens the door for real-time applications working with hand gestures. With this easier accessibility for those in need and a quantity of quality of life functionalities are achievable, like gesture based control of a software.
\par Utilizing this a lot of areas can be improved, by providing an easier environment to work in. One of the most important field in my opinion being teaching, structured or unstructured. It being an old field of research, a lot of ways of conveying information have been theorized and tested, however methods, and way of learning differs from person to person. Because of this difference providing an environment where the creation of different approaches is simplified, could prove useful for those interested in teaching others and also for people who want to learn by providing more choices. While videos are an amazing way of spreading information, and very advanced software's are available, providing different visuals without a third party accessory could still prove challenging. This is the main focus of my paper to create a video recording environment where creating simple visuals on the fly by drawing is made easier. While the main focus is on drawing by the means of hand gestures and hand position, other quality of life features, namely audio level changing by gestures are available.
\par Besides the size of the software, another limitation comes from the usage of the pyaudio module. Since the recording and saving of audio data is not quite straightforward, the application simply saves this at the end of the video recording. This means the video length will have an upper bound based on available memory.
\par While the usage of deep learning models seems promising in order to achieve higher detection precision compared to other methods, there was one big barrier for a long time, which is that running them was very expensive compared to the average hardware available for people. While this paper will dwell in that, a real deep dive is not made, only shown that real-time computation is possible. Although the application takes a considerable hit in frames per second, it is also very much dependent on the computers capabilities. Having said all that on a mid-range machine watchable performance is still achievable, if using the right model.
\par In order to create an application which is capable of providing the aforementioned gesture driven features, appropriate modules are used, namely wave, opencv and pyaudio for video recording and TensorFlow for the utilization of the AI model. In case of the machine learning part for better results an already pretrained model will be used, taking advantage of the transfer learning method.
\par In the following chapters I will go into more detail about the different parts of the software, starting with already existing research about image segmentation algorithms and deep learning models in chapter 2.
\par Following that I am looking into the performance of different machine learning models, taking into account research from the field.
\par In chapter 4 the specifications of the model used in the application will be presented alongside the descriptions about the data collection and preprocessing.
\par The second half of the paper contains the development and structure of the application, starting with the requirements and specifications. After that I will go into detail about the design and testing in the following two chapters.
\par Closing down the paper a chapter will be presented about possible improvements in the future, than drawing the conclusion in the final chapter.